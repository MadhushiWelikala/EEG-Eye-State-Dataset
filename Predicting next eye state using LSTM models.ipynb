{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import LSTM, Dense, Dropout, Activation\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14980, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>eyeDetection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "\n",
       "        P8       T8      FC6       F4       F8      AF4 eyeDetection  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85         b'0'  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10         b'0'  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23         b'0'  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41         b'0'  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46         b'0'  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dataset = arff.loadarff('EEG_Eye_State.arff')\n",
    "df = pd.DataFrame(dataset[0])\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "values = df.values\n",
    "inputs = values[:, :-1]\n",
    "output = values[:, -1]\n",
    "\n",
    "data_array = array(values)\n",
    "input_array = array(inputs)\n",
    "output_array = array(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "      <td>14980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4321.917777</td>\n",
       "      <td>4009.767694</td>\n",
       "      <td>4264.022433</td>\n",
       "      <td>4164.946326</td>\n",
       "      <td>4341.741075</td>\n",
       "      <td>4644.022379</td>\n",
       "      <td>4110.400160</td>\n",
       "      <td>4616.056904</td>\n",
       "      <td>4218.826610</td>\n",
       "      <td>4231.316200</td>\n",
       "      <td>4202.456900</td>\n",
       "      <td>4279.232774</td>\n",
       "      <td>4615.205336</td>\n",
       "      <td>4416.435832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2492.072174</td>\n",
       "      <td>45.941672</td>\n",
       "      <td>44.428052</td>\n",
       "      <td>5216.404632</td>\n",
       "      <td>34.738821</td>\n",
       "      <td>2924.789537</td>\n",
       "      <td>4600.926543</td>\n",
       "      <td>29.292603</td>\n",
       "      <td>2136.408523</td>\n",
       "      <td>38.050903</td>\n",
       "      <td>37.785981</td>\n",
       "      <td>41.544312</td>\n",
       "      <td>1208.369958</td>\n",
       "      <td>5891.285043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1030.770000</td>\n",
       "      <td>2830.770000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>2453.330000</td>\n",
       "      <td>2089.740000</td>\n",
       "      <td>2768.210000</td>\n",
       "      <td>2086.150000</td>\n",
       "      <td>4567.180000</td>\n",
       "      <td>1357.950000</td>\n",
       "      <td>1816.410000</td>\n",
       "      <td>3273.330000</td>\n",
       "      <td>2257.950000</td>\n",
       "      <td>86.666700</td>\n",
       "      <td>1366.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4280.510000</td>\n",
       "      <td>3990.770000</td>\n",
       "      <td>4250.260000</td>\n",
       "      <td>4108.210000</td>\n",
       "      <td>4331.790000</td>\n",
       "      <td>4611.790000</td>\n",
       "      <td>4057.950000</td>\n",
       "      <td>4604.620000</td>\n",
       "      <td>4190.770000</td>\n",
       "      <td>4220.510000</td>\n",
       "      <td>4190.260000</td>\n",
       "      <td>4267.690000</td>\n",
       "      <td>4590.770000</td>\n",
       "      <td>4342.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4294.360000</td>\n",
       "      <td>4005.640000</td>\n",
       "      <td>4262.560000</td>\n",
       "      <td>4120.510000</td>\n",
       "      <td>4338.970000</td>\n",
       "      <td>4617.950000</td>\n",
       "      <td>4070.260000</td>\n",
       "      <td>4613.330000</td>\n",
       "      <td>4199.490000</td>\n",
       "      <td>4229.230000</td>\n",
       "      <td>4200.510000</td>\n",
       "      <td>4276.920000</td>\n",
       "      <td>4603.080000</td>\n",
       "      <td>4354.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4311.790000</td>\n",
       "      <td>4023.080000</td>\n",
       "      <td>4270.770000</td>\n",
       "      <td>4132.310000</td>\n",
       "      <td>4347.180000</td>\n",
       "      <td>4626.670000</td>\n",
       "      <td>4083.590000</td>\n",
       "      <td>4624.100000</td>\n",
       "      <td>4209.230000</td>\n",
       "      <td>4239.490000</td>\n",
       "      <td>4211.280000</td>\n",
       "      <td>4287.180000</td>\n",
       "      <td>4617.440000</td>\n",
       "      <td>4372.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>309231.000000</td>\n",
       "      <td>7804.620000</td>\n",
       "      <td>6880.510000</td>\n",
       "      <td>642564.000000</td>\n",
       "      <td>6474.360000</td>\n",
       "      <td>362564.000000</td>\n",
       "      <td>567179.000000</td>\n",
       "      <td>7264.100000</td>\n",
       "      <td>265641.000000</td>\n",
       "      <td>6674.360000</td>\n",
       "      <td>6823.080000</td>\n",
       "      <td>7002.560000</td>\n",
       "      <td>152308.000000</td>\n",
       "      <td>715897.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AF3            F7            F3            FC5            T7  \\\n",
       "count   14980.000000  14980.000000  14980.000000   14980.000000  14980.000000   \n",
       "mean     4321.917777   4009.767694   4264.022433    4164.946326   4341.741075   \n",
       "std      2492.072174     45.941672     44.428052    5216.404632     34.738821   \n",
       "min      1030.770000   2830.770000   1040.000000    2453.330000   2089.740000   \n",
       "25%      4280.510000   3990.770000   4250.260000    4108.210000   4331.790000   \n",
       "50%      4294.360000   4005.640000   4262.560000    4120.510000   4338.970000   \n",
       "75%      4311.790000   4023.080000   4270.770000    4132.310000   4347.180000   \n",
       "max    309231.000000   7804.620000   6880.510000  642564.000000   6474.360000   \n",
       "\n",
       "                  P7             O1            O2             P8  \\\n",
       "count   14980.000000   14980.000000  14980.000000   14980.000000   \n",
       "mean     4644.022379    4110.400160   4616.056904    4218.826610   \n",
       "std      2924.789537    4600.926543     29.292603    2136.408523   \n",
       "min      2768.210000    2086.150000   4567.180000    1357.950000   \n",
       "25%      4611.790000    4057.950000   4604.620000    4190.770000   \n",
       "50%      4617.950000    4070.260000   4613.330000    4199.490000   \n",
       "75%      4626.670000    4083.590000   4624.100000    4209.230000   \n",
       "max    362564.000000  567179.000000   7264.100000  265641.000000   \n",
       "\n",
       "                 T8           FC6            F4             F8            AF4  \n",
       "count  14980.000000  14980.000000  14980.000000   14980.000000   14980.000000  \n",
       "mean    4231.316200   4202.456900   4279.232774    4615.205336    4416.435832  \n",
       "std       38.050903     37.785981     41.544312    1208.369958    5891.285043  \n",
       "min     1816.410000   3273.330000   2257.950000      86.666700    1366.150000  \n",
       "25%     4220.510000   4190.260000   4267.690000    4590.770000    4342.050000  \n",
       "50%     4229.230000   4200.510000   4276.920000    4603.080000    4354.870000  \n",
       "75%     4239.490000   4211.280000   4287.180000    4617.440000    4372.820000  \n",
       "max     6674.360000   6823.080000   7002.560000  152308.000000  715897.000000  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n",
      "(1079, 10, 15)\n",
      "(1079, 10, 15)\n"
     ]
    }
   ],
   "source": [
    "# normalize features\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#scaled = scaler.fit_transform(values)\n",
    "\n",
    "# reshape data sample\n",
    "data_samples = list()\n",
    "length = 10\n",
    "n = 10785\n",
    "# step over the 10785 in jumps of 10\n",
    "for i in range(0,n,length):\n",
    "\t# grab from i to i + 10\n",
    "\tdata_sample = data_array[i:i+length]\n",
    "\tdata_samples.append(data_sample)\n",
    "print(len(data_samples))\n",
    "\n",
    "data_array = array(data_samples)\n",
    "print(data_array.shape)\n",
    "\n",
    "data_array = array(data_samples)\n",
    "print(data_array.shape)\n",
    "\n",
    "data_array = data_array.reshape((len(data_samples), length, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n",
      "(1079, 10, 14)\n",
      "(1079, 10, 14)\n"
     ]
    }
   ],
   "source": [
    "# reshape input data sample\n",
    "input_samples = list()\n",
    "length = 10\n",
    "n = 10785\n",
    "# step over the 10785 in jumps of 10\n",
    "for i in range(0,n,length):\n",
    "\t# grab from i to i + 10\n",
    "\tinput_sample = input_array[i:i+length]\n",
    "\tinput_samples.append(input_sample)\n",
    "print(len(input_samples))\n",
    "\n",
    "input_array = array(input_samples)\n",
    "print(input_array.shape)\n",
    "\n",
    "input_array = array(input_samples)\n",
    "print(input_array.shape)\n",
    "\n",
    "input_array = input_array.reshape((len(input_samples), length, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079\n",
      "(1079, 10)\n",
      "(1079, 10)\n"
     ]
    }
   ],
   "source": [
    "# reshape output data sample\n",
    "output_samples = list()\n",
    "length = 10\n",
    "n = 10785\n",
    "# step over the 10785 in jumps of 10\n",
    "for i in range(0,n,length):\n",
    "\t# grab from i to i + 10\n",
    "\toutput_sample = output_array[i:i+length]\n",
    "\toutput_samples.append(output_sample)\n",
    "print(len(output_samples))\n",
    "\n",
    "output_array = array(output_samples)\n",
    "print(output_array.shape)\n",
    "\n",
    "output_array = array(output_samples)\n",
    "print(output_array.shape)\n",
    "\n",
    "output_array = output_array.reshape((len(output_samples), length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(776, 10, 14)\n",
      "(216, 10, 14)\n",
      "(776, 10, 1)\n",
      "(216, 10, 1)\n",
      "(87, 10, 14)\n",
      "(87, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "#split data set\n",
    "\n",
    "Train_inputs, Test_inputs, train_output, test_output = train_test_split(input_array, output_array, test_size=0.20, random_state=1,shuffle=False)\n",
    "Train_inputs,valid_inputs,train_output,valid_output = train_test_split(Train_inputs, train_output, test_size=0.10, random_state=1)\n",
    "\n",
    "print(Train_inputs.shape)\n",
    "print(Test_inputs.shape)\n",
    "print(train_output.shape)\n",
    "print(test_output.shape)\n",
    "print(valid_inputs.shape)\n",
    "print(valid_output.shape)\n",
    "\n",
    "#std_scale = preprocessing.StandardScaler().fit(Train_inputs)\n",
    "#train_inputs = std_scale.transform(Train_inputs)\n",
    "#test_inputs = std_scale.transform(Test_inputs)\n",
    "\n",
    "#print(train_inputs.shape)\n",
    "#print(test_inputs.shape)\n",
    "#print(train_output.shape)\n",
    "#print(test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_tf = Train_inputs.reshape(776,10,14)\n",
    "test_inputs_tf = Test_inputs.reshape(216,10,14)\n",
    "train_output_tf = train_output.reshape(776,10,1)\n",
    "test_output_tf = test_output.reshape(216,10,1)\n",
    "\n",
    "batch_size = 1\n",
    "training_split = 0.2\n",
    "num_fields = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 776 samples, validate on 216 samples\n",
      "Epoch 1/500\n",
      "776/776 [==============================] - 31s 40ms/step - loss: 1.6671 - acc: 0.5572 - val_loss: 1.2292 - val_acc: 0.1963\n",
      "Epoch 2/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.7071 - acc: 0.5724 - val_loss: 0.8997 - val_acc: 0.1963\n",
      "Epoch 3/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6994 - acc: 0.5619 - val_loss: 0.5406 - val_acc: 0.8037\n",
      "Epoch 4/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.7240 - acc: 0.5365 - val_loss: 0.5212 - val_acc: 0.8037\n",
      "Epoch 5/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.7166 - acc: 0.5385 - val_loss: 1.0569 - val_acc: 0.1963\n",
      "Epoch 6/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6856 - acc: 0.5959 - val_loss: 1.1052 - val_acc: 0.1963\n",
      "Epoch 7/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6887 - acc: 0.5845 - val_loss: 0.8894 - val_acc: 0.1963\n",
      "Epoch 8/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6745 - acc: 0.5960 - val_loss: 0.7016 - val_acc: 0.1968\n",
      "Epoch 9/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6797 - acc: 0.5862 - val_loss: 0.9076 - val_acc: 0.1963\n",
      "Epoch 10/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6809 - acc: 0.5892 - val_loss: 1.2025 - val_acc: 0.1963\n",
      "Epoch 11/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6775 - acc: 0.5822 - val_loss: 0.8766 - val_acc: 0.1963\n",
      "Epoch 12/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6779 - acc: 0.5964 - val_loss: 0.9644 - val_acc: 0.1963\n",
      "Epoch 13/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6758 - acc: 0.5985 - val_loss: 0.8946 - val_acc: 0.1963\n",
      "Epoch 14/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6746 - acc: 0.6008 - val_loss: 0.8502 - val_acc: 0.1963\n",
      "Epoch 15/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6751 - acc: 0.6004 - val_loss: 0.8718 - val_acc: 0.1963\n",
      "Epoch 16/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6775 - acc: 0.5960 - val_loss: 0.8768 - val_acc: 0.1963\n",
      "Epoch 17/500\n",
      "776/776 [==============================] - 21s 28ms/step - loss: 0.6755 - acc: 0.5997 - val_loss: 0.6504 - val_acc: 0.8037\n",
      "Epoch 18/500\n",
      "776/776 [==============================] - 23s 30ms/step - loss: 0.6848 - acc: 0.5585 - val_loss: 1.0012 - val_acc: 0.1963\n",
      "Epoch 19/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6788 - acc: 0.6008 - val_loss: 0.7673 - val_acc: 0.1963\n",
      "Epoch 20/500\n",
      "776/776 [==============================] - 22s 29ms/step - loss: 0.6749 - acc: 0.6008 - val_loss: 0.7286 - val_acc: 0.1968\n",
      "Epoch 21/500\n",
      "776/776 [==============================] - 23s 30ms/step - loss: 0.6759 - acc: 0.5919 - val_loss: 1.0111 - val_acc: 0.1963\n",
      "Epoch 22/500\n",
      "776/776 [==============================] - 23s 29ms/step - loss: 0.6785 - acc: 0.6008 - val_loss: 0.8579 - val_acc: 0.1963\n",
      "Epoch 23/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6782 - acc: 0.6012 - val_loss: 1.0770 - val_acc: 0.1963\n",
      "Epoch 24/500\n",
      "776/776 [==============================] - 22s 29ms/step - loss: 0.6816 - acc: 0.6008 - val_loss: 0.7252 - val_acc: 0.1968\n",
      "Epoch 25/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6771 - acc: 0.5969 - val_loss: 0.7732 - val_acc: 0.1963\n",
      "Epoch 26/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6758 - acc: 0.6006 - val_loss: 0.7404 - val_acc: 0.1968\n",
      "Epoch 27/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6775 - acc: 0.6000 - val_loss: 0.8682 - val_acc: 0.1963\n",
      "Epoch 28/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6750 - acc: 0.6008 - val_loss: 0.7569 - val_acc: 0.1968\n",
      "Epoch 29/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6758 - acc: 0.6006 - val_loss: 0.9831 - val_acc: 0.1963\n",
      "Epoch 30/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6779 - acc: 0.6006 - val_loss: 0.9009 - val_acc: 0.1963\n",
      "Epoch 31/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6752 - acc: 0.6008 - val_loss: 0.7616 - val_acc: 0.1963\n",
      "Epoch 32/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6770 - acc: 0.6008 - val_loss: 0.9892 - val_acc: 0.1963\n",
      "Epoch 33/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6730 - acc: 0.6008 - val_loss: 0.7651 - val_acc: 0.1963\n",
      "Epoch 34/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6747 - acc: 0.6008 - val_loss: 0.9471 - val_acc: 0.1963\n",
      "Epoch 35/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6765 - acc: 0.6009 - val_loss: 0.9741 - val_acc: 0.1963\n",
      "Epoch 36/500\n",
      "776/776 [==============================] - 22s 29ms/step - loss: 0.6785 - acc: 0.6008 - val_loss: 0.8383 - val_acc: 0.1963\n",
      "Epoch 37/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6743 - acc: 0.6008 - val_loss: 0.7395 - val_acc: 0.1968\n",
      "Epoch 38/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6780 - acc: 0.6005 - val_loss: 0.8282 - val_acc: 0.1963\n",
      "Epoch 39/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6738 - acc: 0.6008 - val_loss: 0.7118 - val_acc: 0.1972\n",
      "Epoch 40/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6853 - acc: 0.5951 - val_loss: 0.7421 - val_acc: 0.1968\n",
      "Epoch 41/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6750 - acc: 0.6008 - val_loss: 0.7808 - val_acc: 0.1963\n",
      "Epoch 42/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6756 - acc: 0.6008 - val_loss: 0.8368 - val_acc: 0.1963\n",
      "Epoch 43/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6748 - acc: 0.6008 - val_loss: 0.9522 - val_acc: 0.1963\n",
      "Epoch 44/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6735 - acc: 0.6008 - val_loss: 0.7840 - val_acc: 0.1963\n",
      "Epoch 45/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6742 - acc: 0.6008 - val_loss: 0.9708 - val_acc: 0.1963\n",
      "Epoch 46/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6792 - acc: 0.6008 - val_loss: 0.9255 - val_acc: 0.1963\n",
      "Epoch 47/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6757 - acc: 0.6008 - val_loss: 0.9670 - val_acc: 0.1963\n",
      "Epoch 48/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6763 - acc: 0.6008 - val_loss: 0.7645 - val_acc: 0.1963\n",
      "Epoch 49/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6748 - acc: 0.6008 - val_loss: 0.8546 - val_acc: 0.1963\n",
      "Epoch 50/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6778 - acc: 0.6008 - val_loss: 0.9360 - val_acc: 0.1963\n",
      "Epoch 51/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6776 - acc: 0.6008 - val_loss: 0.8507 - val_acc: 0.1963\n",
      "Epoch 52/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6737 - acc: 0.6008 - val_loss: 0.8402 - val_acc: 0.1963\n",
      "Epoch 53/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6742 - acc: 0.5997 - val_loss: 0.9451 - val_acc: 0.1963\n",
      "Epoch 54/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6770 - acc: 0.6008 - val_loss: 0.8464 - val_acc: 0.1963\n",
      "Epoch 55/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6743 - acc: 0.6008 - val_loss: 0.8036 - val_acc: 0.1963\n",
      "Epoch 56/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6743 - acc: 0.6008 - val_loss: 0.8488 - val_acc: 0.1963\n",
      "Epoch 57/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6767 - acc: 0.6008 - val_loss: 0.7823 - val_acc: 0.1968\n",
      "Epoch 58/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6758 - acc: 0.6008 - val_loss: 0.9037 - val_acc: 0.1963\n",
      "Epoch 59/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6749 - acc: 0.6008 - val_loss: 0.7996 - val_acc: 0.1963\n",
      "Epoch 60/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6733 - acc: 0.6008 - val_loss: 1.0165 - val_acc: 0.1963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "776/776 [==============================] - 19s 25ms/step - loss: 0.6824 - acc: 0.6008 - val_loss: 0.8228 - val_acc: 0.1963\n",
      "Epoch 62/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6739 - acc: 0.6008 - val_loss: 0.8589 - val_acc: 0.1963\n",
      "Epoch 63/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6756 - acc: 0.6008 - val_loss: 0.9633 - val_acc: 0.1963\n",
      "Epoch 64/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6765 - acc: 0.6008 - val_loss: 0.8936 - val_acc: 0.1963\n",
      "Epoch 65/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6745 - acc: 0.6008 - val_loss: 0.7962 - val_acc: 0.1968\n",
      "Epoch 66/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6753 - acc: 0.6008 - val_loss: 0.8003 - val_acc: 0.1963\n",
      "Epoch 67/500\n",
      "776/776 [==============================] - 20s 25ms/step - loss: 0.6740 - acc: 0.6008 - val_loss: 0.9078 - val_acc: 0.1963\n",
      "Epoch 68/500\n",
      "776/776 [==============================] - 22s 29ms/step - loss: 0.6750 - acc: 0.6008 - val_loss: 0.8927 - val_acc: 0.1963\n",
      "Epoch 69/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6745 - acc: 0.6008 - val_loss: 0.8211 - val_acc: 0.1963\n",
      "Epoch 70/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6737 - acc: 0.6008 - val_loss: 0.7934 - val_acc: 0.1968\n",
      "Epoch 71/500\n",
      "776/776 [==============================] - 20s 26ms/step - loss: 0.6753 - acc: 0.6008 - val_loss: 0.9062 - val_acc: 0.1963\n",
      "Epoch 72/500\n",
      "776/776 [==============================] - 22s 29ms/step - loss: 0.6766 - acc: 0.6008 - val_loss: 0.8045 - val_acc: 0.1968\n",
      "Epoch 73/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6746 - acc: 0.6008 - val_loss: 0.8206 - val_acc: 0.1968\n",
      "Epoch 74/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6737 - acc: 0.6008 - val_loss: 0.8391 - val_acc: 0.1968\n",
      "Epoch 75/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6740 - acc: 0.6008 - val_loss: 0.8625 - val_acc: 0.1968\n",
      "Epoch 76/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6750 - acc: 0.6008 - val_loss: 0.8645 - val_acc: 0.1968\n",
      "Epoch 77/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6741 - acc: 0.6008 - val_loss: 0.7451 - val_acc: 0.1968\n",
      "Epoch 78/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6766 - acc: 0.6009 - val_loss: 0.8219 - val_acc: 0.1968\n",
      "Epoch 79/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6736 - acc: 0.6008 - val_loss: 0.9401 - val_acc: 0.1963\n",
      "Epoch 80/500\n",
      "776/776 [==============================] - 23s 29ms/step - loss: 0.6752 - acc: 0.6008 - val_loss: 0.7769 - val_acc: 0.1968\n",
      "Epoch 81/500\n",
      "776/776 [==============================] - 24s 31ms/step - loss: 0.6745 - acc: 0.6008 - val_loss: 0.9133 - val_acc: 0.1968\n",
      "Epoch 82/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6762 - acc: 0.6008 - val_loss: 0.9104 - val_acc: 0.1968\n",
      "Epoch 83/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6752 - acc: 0.6008 - val_loss: 0.9335 - val_acc: 0.1963\n",
      "Epoch 84/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6762 - acc: 0.6008 - val_loss: 0.9228 - val_acc: 0.1968\n",
      "Epoch 85/500\n",
      "776/776 [==============================] - 22s 29ms/step - loss: 0.6743 - acc: 0.6008 - val_loss: 0.8242 - val_acc: 0.1968\n",
      "Epoch 86/500\n",
      "776/776 [==============================] - 22s 29ms/step - loss: 0.6737 - acc: 0.6008 - val_loss: 0.8336 - val_acc: 0.1968\n",
      "Epoch 87/500\n",
      "776/776 [==============================] - 23s 30ms/step - loss: 0.6737 - acc: 0.6008 - val_loss: 0.8536 - val_acc: 0.1968\n",
      "Epoch 88/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6744 - acc: 0.6008 - val_loss: 0.8952 - val_acc: 0.1968\n",
      "Epoch 89/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6749 - acc: 0.6008 - val_loss: 0.7732 - val_acc: 0.1968\n",
      "Epoch 90/500\n",
      "776/776 [==============================] - 21s 27ms/step - loss: 0.6766 - acc: 0.6008 - val_loss: 0.7927 - val_acc: 0.1968\n",
      "Epoch 91/500\n",
      "776/776 [==============================] - 24s 30ms/step - loss: 0.6736 - acc: 0.6008 - val_loss: 0.8409 - val_acc: 0.1968\n",
      "Epoch 92/500\n",
      "776/776 [==============================] - 22s 28ms/step - loss: 0.6743 - acc: 0.6008 - val_loss: 0.7842 - val_acc: 0.1968\n",
      "Epoch 93/500\n",
      "384/776 [=============>................] - ETA: 9s - loss: 0.6732 - acc: 0.6049 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-deeceb34c17a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_output_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_output_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1214\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m     updated = session.run(\n\u001b[1;32m-> 2824\u001b[1;33m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2825\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1024,return_sequences=True,implementation=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(1024,return_sequences=True,implementation=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_inputs_tf, train_output_tf, epochs=20, batch_size= 128,verbose=1,validation_data=(test_inputs_tf, test_output_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
